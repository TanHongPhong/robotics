# Ollama Configuration
OLLAMA_HOST=http://127.0.0.1:11434
OLLAMA_MODEL=llama3.1:8b-instruct-q4_K_M
OLLAMA_TEMPERATURE=0.1
OLLAMA_TOP_P=0.9
OLLAMA_NUM_CTX=4096

# GPU Settings for CUDA (Optimized for Speed)
OLLAMA_NUM_GPU=1
OLLAMA_GPU_LAYERS=-1
OLLAMA_NUM_PARALLEL=2
OLLAMA_MAX_LOADED_MODELS=2

# STT Model Configuration (separate from main chat model)
STT_MODEL=qwen2.5:1.5b-instruct
STT_TEMPERATURE=0.2

# Flask Configuration  
FLASK_PORT=5000
FLASK_DEBUG=True

# Deepgram STT Configuration
DEEPGRAM_API_KEY=86d63f03b325e001bd81e60e5a0265c3b75ad4cc
DG_LANGUAGE=vi
DG_SAMPLE_RATE=16000
DG_BLOCK_MS=50
DG_FLUSH_MS=1200
DG_STOP_GRACE_S=6.0
STREAM_LOG_MAX=600
